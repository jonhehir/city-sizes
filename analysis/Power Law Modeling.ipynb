{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "\n",
    "You need to have the `powerlaw` package installed in order to run any of the following. Installation is easy through `pip`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install powerlaw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Analysis\n",
    "\n",
    "## Basic Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import data # local module\n",
    "import resulthelpers # local module\n",
    "import powerlaw\n",
    "import numpy\n",
    "numpy.seterr(divide=\"ignore\", invalid=\"ignore\") # https://github.com/jeffalstott/powerlaw/issues/25"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parameter Selection\n",
    "\n",
    "For a given dataset (namely the CCA block and CCA raster datasets), we want to find the parameter values for which the power law fit is least sensitive. So we run fits on each possible set of parameters and then check for the mean and standard deviation of the $\\alpha$ and $x_\\text{min}$ values while holding a given parameter value constant."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare_params(get_params, get_data, discrete):\n",
    "    from pandas import DataFrame\n",
    "    records = []\n",
    "    params = get_params()\n",
    "    for args in params.itertuples(index=False):\n",
    "        data = get_data(*args)\n",
    "        fit = powerlaw.Fit(data[\"population\"], discrete=discrete, estimate_discrete=True, verbose=False)\n",
    "        record = args._asdict()\n",
    "        record[\"alpha\"] = fit.power_law.alpha\n",
    "        record[\"xmin\"] = fit.xmin\n",
    "        record[\"n\"] = (data[\"population\"] >= fit.xmin).sum()\n",
    "        records.append(record)\n",
    "    \n",
    "    return DataFrame.from_records(records)\n",
    "\n",
    "%time param_results = compare_params(data.get_cca_raster_params, data.get_cca_raster_data, discrete=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_results.groupby(\"dmin\").agg({ \"alpha\": [\"mean\", \"std\"], \"xmin\": [\"mean\", \"std\"] })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "param_results.groupby(\"l\").agg({ \"alpha\": [\"mean\", \"std\"], \"xmin\": [\"mean\", \"std\"] })"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Defining the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Datasets to process\n",
    "# Beware: this variable is used in a few cells below.\n",
    "datasets = {\n",
    "    \"CCA Tract, 1990/2000\": {\n",
    "        \"get_data\": data.get_cca_tract_19902000_data,\n",
    "        \"params\": [3000],\n",
    "        \"columns\": [\"population\", \"area\"],\n",
    "        \"discrete\": [\"population\"]\n",
    "    },\n",
    "    \"CCA Tract (2+), 1990/2000\": {\n",
    "        \"get_data\": data.get_cca_tract_19902000_data,\n",
    "        \"params\": [3000, 2],\n",
    "        \"columns\": [\"population\", \"area\"],\n",
    "        \"discrete\": [\"population\"]\n",
    "    },\n",
    "    \"CCA Tract (3+), 1990/2000\": {\n",
    "        \"get_data\": data.get_cca_tract_19902000_data,\n",
    "        \"params\": [3000, 3],\n",
    "        \"columns\": [\"population\", \"area\"],\n",
    "        \"discrete\": [\"population\"]\n",
    "    },\n",
    "    \"CCA Tract\": {\n",
    "        \"get_data\": data.get_cca_tract_data,\n",
    "        \"params\": [3000],\n",
    "        \"columns\": [\"population\", \"area\", \"jobs\"],\n",
    "        \"discrete\": [\"population\", \"jobs\"]\n",
    "    },\n",
    "    \"CCA Tract (2+)\": {\n",
    "        \"get_data\": data.get_cca_tract_data,\n",
    "        \"params\": [3000, 2],\n",
    "        \"columns\": [\"population\", \"area\", \"jobs\"],\n",
    "        \"discrete\": [\"population\", \"jobs\"]\n",
    "    },\n",
    "    \"CCA Tract (3+)\": {\n",
    "        \"get_data\": data.get_cca_tract_data,\n",
    "        \"params\": [3000, 3],\n",
    "        \"columns\": [\"population\", \"area\", \"jobs\"],\n",
    "        \"discrete\": [\"population\", \"jobs\"]\n",
    "    },\n",
    "   \"CCA Raster\": {\n",
    "        \"get_data\": data.get_cca_raster_data,\n",
    "        \"params\": [1000, 5],\n",
    "        \"columns\": [\"population\", \"area\", \"jobs\"],\n",
    "        \"discrete\": []\n",
    "    },\n",
    "    \"CCA Block\": {\n",
    "        \"get_data\": data.get_cca_block_data,\n",
    "        \"params\": [1000, 1000],\n",
    "        \"columns\": [\"population\", \"area\", \"jobs\"],\n",
    "        \"discrete\": [\"population\", \"jobs\"]\n",
    "    },\n",
    "    \"CCA Street Network\": {\n",
    "        \"get_data\": data.get_cca_street_network_data,\n",
    "        \"params\": [\"full\", 100000],\n",
    "        \"columns\": [\"population\", \"area\", \"jobs\"],\n",
    "        \"discrete\": []\n",
    "    },\n",
    "    \"Census UA/UC\": {\n",
    "        \"get_data\": data.get_census_uauc_data,\n",
    "        \"params\": [],\n",
    "        \"columns\": [\"population\", \"area\", \"jobs\"],\n",
    "        \"discrete\": [\"population\", \"jobs\"]\n",
    "    },\n",
    "    \"Census Place\": {\n",
    "        \"get_data\": data.get_census_place_data,\n",
    "        \"params\": [],\n",
    "        \"columns\": [\"population\", \"area\", \"jobs\"],\n",
    "        \"discrete\": [\"population\", \"jobs\"]\n",
    "    },\n",
    "    \"Census CBSA\": {\n",
    "        \"get_data\": data.get_census_cbsa_data,\n",
    "        \"params\": [],\n",
    "        \"columns\": [\"population\", \"area\", \"jobs\"],\n",
    "        \"discrete\": [\"population\", \"jobs\"]\n",
    "    },\n",
    "    \"Census CBSA, 2000\": {\n",
    "        \"get_data\": data.get_census_cbsa_2000_data,\n",
    "        \"params\": [],\n",
    "        \"columns\": [\"population\"],\n",
    "        \"discrete\": [\"population\"]\n",
    "    },\n",
    "    \"Census CBSA, 1990\": {\n",
    "        \"get_data\": data.get_census_cbsa_1990_data,\n",
    "        \"params\": [],\n",
    "        \"columns\": [\"population\"],\n",
    "        \"discrete\": [\"population\"]\n",
    "    }\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview of the Datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_dataset_summary(dataset):\n",
    "    df = dataset[\"get_data\"](*dataset[\"params\"])\n",
    "    print(\"    number of cities: \" + str(len(df)))\n",
    "    for col in dataset[\"columns\"]:\n",
    "        print(\"  \" + col)\n",
    "        print(\"    sum: \" + str(df[col].sum()))\n",
    "        print(\"    min: \" + str(df[col].min()))\n",
    "        print(\"    max: \" + str(df[col].max()))\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for name, dataset in datasets.items():\n",
    "    print(name)\n",
    "    print_dataset_summary(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fitting the Models\n",
    "\n",
    "For each dataset (and each column within that dataset), we run separate fits for:\n",
    "\n",
    "- Upper tail: power law and lognormal\n",
    "    - $x_\\text{min}$ is determined by minimal KS for power law fit.\n",
    "- Untruncated distribution: power law and lognormal\n",
    "    - $x_\\text{min}$ is explicitly set to the minimum value in the dataset.\n",
    "    - If the dataset takes only discrete (integer) values, $x_\\text{min}$ is set to $max \\{ 10, x_\\text{min} \\}$ to avoid discrete estimation error. We call these results \"semitruncated.\"\n",
    "\n",
    "Since this produces a lot of resultsâ€”and since we want graphs for everything tooâ€”we output all the results to files in `./results`. Once this is done, you can pull it back into a Pandas dataframe below for easier viewing.\n",
    "\n",
    "Before running this, you may want to ensure that a `results` directory actually exists. This takes almost a half hour for me to run from within a small VirtualBox VM. Most of that time was spent on the Natural Cities data. You can skip the slow datasets by commenting them out of the `datasets` definition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_models(dataframe, datasetname, discrete, col=\"population\", outputdir=\".\", untruncated=False, xmin=None):\n",
    "    import os\n",
    "    import re\n",
    "    import matplotlib.pyplot as plt\n",
    "    \n",
    "    data = dataframe[col]\n",
    "    \n",
    "    semitruncated = False\n",
    "    if xmin is None and untruncated:\n",
    "        # per Clauset et al., discrete estimation is not super reliable with small numbers\n",
    "        xmin = min(data[data > 0])\n",
    "        if discrete and xmin < 10:\n",
    "            xmin = 10\n",
    "            semitruncated = True\n",
    "    # else: calculate optimal xmin by PL fit\n",
    "    \n",
    "    results = powerlaw.Fit(data, discrete=discrete, estimate_discrete=True, xmin=xmin, verbose=False)\n",
    "    \n",
    "    if untruncated:\n",
    "        fitpart = \"full\"\n",
    "    elif not xmin is None:\n",
    "        fitpart = \"min\" + str(xmin)\n",
    "    else:\n",
    "        fitpart = \"tail\"\n",
    "    if semitruncated:\n",
    "        fitpart += \"-semi\"\n",
    "    discretestr = \"discrete\" if discrete else \"continuous\"\n",
    "    filename = os.path.join(outputdir, re.sub(\"[^a-z0-9]\", \"\", datasetname.lower()) + \"-\" + col + \"-\" + fitpart)\n",
    "    with open(filename + \".tsv\", \"w\") as f:\n",
    "        # headers. pretty!\n",
    "        f.write(\"batchid\\tdataset\\tcolumn\\tfitpart\\tcontinuity\\tn_original\\tn\\tn_tail\\tx_min\\talpha\\tplsigma\\tmu\\tlnsigma\\tlratio\\tp_lratio\\tks_pl\\tks_ln\\n\")\n",
    "        \n",
    "        n_tail = (data >= results.xmin).sum()\n",
    "        batchid = resulthelpers.batch_id(name=datasetname, col=col, alpha=results.power_law.alpha,\n",
    "                                         x_min=results.xmin, n=len(data), n_tail=n_tail.item())\n",
    "        \n",
    "        f.write(batchid + \"\\t\")\n",
    "        f.write(datasetname + \"\\t\")\n",
    "        f.write(col + \"\\t\")\n",
    "        f.write(fitpart + \"\\t\")\n",
    "        f.write(discretestr + \"\\t\")\n",
    "        f.write(str(data.count()) + \"\\t\")\n",
    "        n = (data >= xmin).sum() if semitruncated else data.count() # n (may be less than n_original when semitruncated)\n",
    "        f.write(str(n) + \"\\t\")\n",
    "        f.write(str(n_tail) + \"\\t\")\n",
    "        f.write(str(results.xmin) + \"\\t\")\n",
    "        f.write(str(results.power_law.alpha) + \"\\t\")\n",
    "        f.write(str(results.power_law.sigma) + \"\\t\")\n",
    "        f.write(str(results.lognormal.mu) + \"\\t\")\n",
    "        f.write(str(results.lognormal.sigma) + \"\\t\")\n",
    "        \n",
    "        ratio, p = results.distribution_compare(\"power_law\", \"lognormal\")\n",
    "        f.write(str(ratio) + \"\\t\") # pl:ln likelihood ratio\n",
    "        f.write(str(p) + \"\\t\") # likelihood ratio p-value\n",
    "        \n",
    "        f.write(str(results.power_law.KS()) + \"\\t\")\n",
    "        f.write(str(results.lognormal.KS()) + \"\\n\")\n",
    "    \n",
    "    fig = plt.figure()\n",
    "    ax = fig.add_subplot(111)\n",
    "    ax.set_xlabel(datasetname + \" \" + col)\n",
    "    ax.set_ylabel(\"CCDF\")\n",
    "    ccdf = results.ccdf()\n",
    "    ax.plot(ccdf[0], ccdf[1], '.', color=\"#00000030\", markersize=8, markeredgewidth=0)\n",
    "    \n",
    "    # PL and LN:\n",
    "    #results.power_law.plot_ccdf(ax=ax, color=\"#ff6600\", linewidth=1.5, label=\"PL\")\n",
    "    #results.lognormal_positive.plot_ccdf(ax=ax, color=\"#0099cc\", linewidth=1.5, label=\"LN\")\n",
    "    #plt.legend()\n",
    "    \n",
    "    # PL only:\n",
    "    results.power_law.plot_ccdf(ax=ax, color=\"#ff6600\", linewidth=1.5)\n",
    "    \n",
    "    fig.savefig(filename + \".png\", bbox_inches=\"tight\", dpi=300)\n",
    "    fig.savefig(filename + \".pdf\", bbox_inches=\"tight\")\n",
    "    plt.close()\n",
    "    \n",
    "    if fitpart == \"tail\":\n",
    "        fig = plt.figure()\n",
    "        ax = fig.add_subplot(111)\n",
    "        ax.set_xlabel(\"$x_{min}$ (\" + datasetname + \" \" + col + \")\")\n",
    "        ax.set_ylabel(\"Î± (Â±Ïƒ)\")\n",
    "        ax.set_ylim([0, 4])\n",
    "        ax.set_xscale(\"log\")\n",
    "        ax.plot(results.xmins, results.alphas, color=\"#774499\")\n",
    "        ax.fill_between(results.xmins, results.alphas+results.sigmas, results.alphas-results.sigmas, color=\"#77449930\", linewidth=0)\n",
    "        ax.axhline(2, color=\"#000000a0\", linewidth=1, linestyle=\"dotted\")\n",
    "        ax.axhline(results.power_law.alpha, color=\"#000000\", linewidth=1)\n",
    "        ax.axvline(results.xmin, color=\"#000000\", linewidth=1)\n",
    "        \n",
    "        ax2 = ax.twinx()\n",
    "        ax2.set_ylim([0, 1])\n",
    "        ax2.set_ylabel(\"KS\", color=\"#ee5555\")\n",
    "        ax2.tick_params(\"y\", colors=\"#ee5555\")\n",
    "        ax2.plot(results.xmins, results.Ds, color=\"#ee5555\")\n",
    "        \n",
    "        fig.savefig(filename + \"-fits.png\", bbox_inches=\"tight\", dpi=300)\n",
    "        fig.savefig(filename + \"-fits.pdf\", bbox_inches=\"tight\")\n",
    "        plt.close()\n",
    "\n",
    "for name, dataset in datasets.items():\n",
    "    df = dataset[\"get_data\"](*dataset[\"params\"])\n",
    "    for col in dataset[\"columns\"]:\n",
    "        discrete = col in dataset[\"discrete\"]\n",
    "        fit_models(df, col=col, discrete=discrete, datasetname=name, outputdir=\"results\")\n",
    "        fit_models(df, col=col, discrete=discrete, datasetname=name, untruncated=True, outputdir=\"results\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_df = resulthelpers.load_basic_results(\"results/*.tsv\")\n",
    "result_df.sort_values([\"dataset\", \"column\", \"fitpart\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bootstrapping\n",
    "\n",
    "To get a p-values for the power law fits, we perform the bootstrapping test described in Clauset et al. 2007. But that's way too slow to run in here.\n",
    "\n",
    "Instead, we (crudely) generate batch files to run through SLURM on a high-performance cluster. Then once those results are run, we aggregate them into a single TSV, and load it back in here for viewing and comparing with the empirical data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def write_bootstrap_batch_files():\n",
    "    # This is pretty ugly.\n",
    "    i = 0\n",
    "    for name, dataset in datasets.items():\n",
    "        df = dataset[\"get_data\"](*dataset[\"params\"])\n",
    "        for col in dataset[\"columns\"]:\n",
    "            i += 1\n",
    "            args = []\n",
    "            \n",
    "            tail_result = result_df.query(\"dataset=='\" + name + \"' and column=='\" + col + \"' and fitpart=='tail'\")\n",
    "            xmin = tail_result[\"x_min\"][0]\n",
    "            \n",
    "            batchid = str(tail_result[\"batchid\"][0])\n",
    "            args.append(str(tail_result[\"alpha\"][0]))\n",
    "            args.append(str(tail_result[\"x_min\"][0]))\n",
    "            args.append(str(tail_result[\"n_original\"][0]))\n",
    "            args.append(str(tail_result[\"n_tail\"][0]))\n",
    "            args.append(batchid)\n",
    "            \n",
    "            args.append(\"--trials 625\")\n",
    "            \n",
    "            if col in dataset[\"discrete\"]:\n",
    "                args.append(\"--discrete\")\n",
    "            \n",
    "            with open(\"batch/\" + str(i) + \".sh\", \"w\") as f:\n",
    "                f.write(\"#!/bin/bash\\n\")\n",
    "                f.write(\"#SBATCH --partition=batch\\n\")\n",
    "                f.write(\"#SBATCH --cpus-per-task=20\\n\")\n",
    "                f.write(\"#SBATCH --ntasks=4\\n\")\n",
    "                if name != \"CCA Street Network\": # those take forever...\n",
    "                    f.write(\"#SBATCH --time=6:00:00\\n\")\n",
    "                f.write(\"#SBATCH --output=results/%j.out\\n\\n\")\n",
    "                f.write(\"# \" + name + \" \" + col + \"\\n\")\n",
    "                \n",
    "                f.write(\"srun /path/to/python simulate_powerlaw.py \" + \" \".join(map(str, args)))\n",
    "            \n",
    "            lower_tail = df[col][df[col] < xmin]\n",
    "            numpy.save(\"batch/\" + batchid + \".npy\", lower_tail)\n",
    "\n",
    "write_bootstrap_batch_files()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
